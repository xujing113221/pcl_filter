% ---------------------------------------------------------------------
\chapter{Introduction}
% ---------------------------------------------------------------------
Robots are becoming more important in everyday live. Because robots usually work in  a dynamic environments,The robot has to adapt its paths according to the changing environment.For this reason motion planning is an important part for robotics research. In this thesis an algorithm is developed which can create an environment representation suitable for a motion planning algorithm based on point clouds received from a capturing device.
\section{ROS}
ROS (Robot Operating System) is an open source system for operating robots on a computer. A ROS system usually consists of a large number of nodes, any of which can communicate with other nodes in a publish/subscribe manner. As a flexible operating system, the nodes on ROS have great arbitrariness. They can be located on different computers or even on different networks.
In this algorithm, first we have an administrator (ROS Master) to manage our entire system, and then we need to establish three nodes, namely the camera node, the image processing node in the robot, and the display node on the computer. Then, under the management of ROS Master, the camera node (Camera Node) initiates a session (Topic) to send image information, and at the same time, the other two nodes subscribe to this session (Topic)(For example picture 2.1). 

\section{PCL}
The Point Cloud Library (PCL) is a standalone, large scale, open project for 2D/3D image and point cloud processing. PCL is released under the terms of the BSD license, and thus free for commercial and research use.
\section{D435i}
In this experiment, we used two binocular cameras to obtain point cloud depth information to synthesize objects. We tested several different cameras.
-The Intel Realsense SR300 camera uses a structured camera. Each camera emits a light signal of a certain frequency, and then uses the reflection of light to obtain depth information. Therefore, when two cameras work at the same time, light interference will inevitably occur.
-Kinect is a Tof camera and must emit a continuous laser, so there will be interference. In addition, Kinect is too large, which is not conducive to laboratory placement and measurement.
-The principle of RealsenseD455 is binocular stereo vision. Do not rely on reflected light to measure depth information, but the minimum measurement distance is 0.4 meters. The experimental environment we require is less than 0.4 meters, so it is not suitable.
- D435 This kind of camera is a binocular depth camera, it is based on the principle of parallax to obtain the three-dimensional geometric information of the object, and will not actively emit light, so two identical D435 will not interfere with each other. And the minimum measurement distance of D435i is 0.1 meters.
-Realsense D435i has the same principle and structure as D435, but D435i has built-in IMU (D435 has no built-in IMU).
So I chose D435i as the camera for this experiment

